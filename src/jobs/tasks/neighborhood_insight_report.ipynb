{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abcdf250",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession, DataFrame\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "dbutils.widgets.text(\"catalog\", \"\")\n",
    "dbutils.widgets.text(\"schema\", \"\")\n",
    "dbutils.widgets.text(\"jobs_schema\", \"\")\n",
    "\n",
    "catalog = dbutils.widgets.get(\"catalog\")\n",
    "schema = dbutils.widgets.get(\"schema\")\n",
    "jobs_schema = dbutils.widgets.get(\"jobs_schema\")\n",
    "\n",
    "if not catalog or not schema or not jobs_schema:\n",
    "    raise ValueError(\"Missing required widget: catalog, schema, or jobs_schema\")\n",
    "\n",
    "trend_table = f\"{catalog}.{schema}.go_neighborhood_trends\"\n",
    "report_table = f\"{jobs_schema}.neighborhood_insight_reports\"\n",
    "\n",
    "class InsightReportProcessor:\n",
    "    def __init__(self, spark: SparkSession, trend_table: str, report_table: str):\n",
    "        self.spark = spark\n",
    "        self.trend_table = trend_table\n",
    "        self.report_table = report_table\n",
    "\n",
    "    def generate_neighborhood_insights(self, trend_df: DataFrame) -> DataFrame:\n",
    "        return (\n",
    "            trend_df.withColumn(\"report_month\", F.date_trunc(\"month\", F.current_timestamp()))\n",
    "            .groupBy(\"borough\", \"report_month\")\n",
    "            .agg(\n",
    "                F.round(F.max(\"avg_median_income_eur\"), 2).alias(\"max_median_income_eur\"),\n",
    "                F.round(F.avg(\"avg_population_density_per_sqm\"), 2).alias(\"avg_population_density_per_sqm\")\n",
    "            )\n",
    "        )\n",
    "\n",
    "    def save_insight_report(self, df: DataFrame) -> None:\n",
    "        df.write.format(\"delta\").mode(\"append\").saveAsTable(self.report_table)\n",
    "\n",
    "processor = InsightReportProcessor(spark, trend_table, report_table)\n",
    "trend_df = spark.table(trend_table)\n",
    "report_df = processor.generate_neighborhood_insights(trend_df)\n",
    "processor.save_insight_report(report_df)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
